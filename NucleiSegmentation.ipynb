{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NucleiSegmentation.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMXLncCslMB/bwFgptoNhL7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Wildan-Alrasyid/NucleiSegmentation/blob/master/NucleiSegmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Requirements**"
      ],
      "metadata": {
        "id": "ojXanPz17wQz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lqH6L2xYfbt-",
        "outputId": "e5ad82e9-de07-4f28-9084-15b21108b385"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'NucleiSegmentation'...\n",
            "remote: Enumerating objects: 171, done.\u001b[K\n",
            "remote: Counting objects: 100% (78/78), done.\u001b[K\n",
            "remote: Compressing objects: 100% (40/40), done.\u001b[K\n",
            "remote: Total 171 (delta 40), reused 38 (delta 38), pack-reused 93\u001b[K\n",
            "Receiving objects: 100% (171/171), 3.46 MiB | 3.14 MiB/s, done.\n",
            "Resolving deltas: 100% (47/47), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/Wildan-Alrasyid/NucleiSegmentation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/NucleiSegmentation"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XkL1uSsof1BK",
        "outputId": "74565f81-286e-41ab-9378-cc7fc15952e1"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/NucleiSegmentation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install dominate\n",
        "!pip install scipy==1.1.0\n",
        "!pip install pytorch torchvision cudatoolkit==10.1 \n",
        "!pip install visdom"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPE42_w6gFG9",
        "outputId": "929f9e54-0728-4def-b11e-e817a3ee30f0"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting dominate\n",
            "  Downloading dominate-2.6.0-py2.py3-none-any.whl (29 kB)\n",
            "Installing collected packages: dominate\n",
            "Successfully installed dominate-2.6.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting scipy==1.1.0\n",
            "  Downloading scipy-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (31.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 31.2 MB 1.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8.2 in /usr/local/lib/python3.7/dist-packages (from scipy==1.1.0) (1.21.6)\n",
            "Installing collected packages: scipy\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.4.1\n",
            "    Uninstalling scipy-1.4.1:\n",
            "      Successfully uninstalled scipy-1.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "pymc3 3.11.4 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "plotnine 0.6.0 requires scipy>=1.2.0, but you have scipy 1.1.0 which is incompatible.\n",
            "jax 0.3.8 requires scipy>=1.2.1, but you have scipy 1.1.0 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed scipy-1.1.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch\n",
            "  Downloading pytorch-1.0.2.tar.gz (689 bytes)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (0.12.0+cu113)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement cudatoolkit==10.1 (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for cudatoolkit==10.1\u001b[0m\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting visdom\n",
            "  Downloading visdom-0.1.8.9.tar.gz (676 kB)\n",
            "\u001b[K     |████████████████████████████████| 676 kB 31.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.8 in /usr/local/lib/python3.7/dist-packages (from visdom) (1.21.6)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from visdom) (1.1.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from visdom) (2.23.0)\n",
            "Requirement already satisfied: tornado in /usr/local/lib/python3.7/dist-packages (from visdom) (5.1.1)\n",
            "Requirement already satisfied: pyzmq in /usr/local/lib/python3.7/dist-packages (from visdom) (23.1.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from visdom) (1.15.0)\n",
            "Collecting jsonpatch\n",
            "  Downloading jsonpatch-1.32-py2.py3-none-any.whl (12 kB)\n",
            "Collecting torchfile\n",
            "  Downloading torchfile-0.1.0.tar.gz (5.2 kB)\n",
            "Collecting websocket-client\n",
            "  Downloading websocket_client-1.3.2-py3-none-any.whl (54 kB)\n",
            "\u001b[K     |████████████████████████████████| 54 kB 3.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.7/dist-packages (from visdom) (7.1.2)\n",
            "Collecting jsonpointer>=1.9\n",
            "  Downloading jsonpointer-2.3-py2.py3-none-any.whl (7.8 kB)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->visdom) (2022.6.15)\n",
            "Building wheels for collected packages: visdom, torchfile\n",
            "  Building wheel for visdom (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for visdom: filename=visdom-0.1.8.9-py3-none-any.whl size=655250 sha256=3be2fb59d7c17e64c7ef6ffdc0666b50d14feb96ee9eca7b337edfbec3bb7ab9\n",
            "  Stored in directory: /root/.cache/pip/wheels/2d/d1/9b/cde923274eac9cbb6ff0d8c7c72fe30a3da9095a38fd50bbf1\n",
            "  Building wheel for torchfile (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torchfile: filename=torchfile-0.1.0-py3-none-any.whl size=5709 sha256=ce666bdb8f6bcf03991fb66b518e1c727ee4763c348ff323c75f8aeb00132503\n",
            "  Stored in directory: /root/.cache/pip/wheels/ac/5c/3a/a80e1c65880945c71fd833408cd1e9a8cb7e2f8f37620bb75b\n",
            "Successfully built visdom torchfile\n",
            "Installing collected packages: jsonpointer, websocket-client, torchfile, jsonpatch, visdom\n",
            "Successfully installed jsonpatch-1.32 jsonpointer-2.3 torchfile-0.1.0 visdom-0.1.8.9 websocket-client-1.3.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Delete semua file dengan format .pyc**"
      ],
      "metadata": {
        "id": "Oqs1Xx8R8EuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list_pyc=[\"/content/NucleiSegmentation/options\",\"/content/NucleiSegmentation/util\"]"
      ],
      "metadata": {
        "id": "V3D8gR0OgPtE"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "for name in list_pyc:\n",
        "  dir_name = name\n",
        "  test = os.listdir(dir_name)\n",
        "\n",
        "  for item in test:\n",
        "      if item.endswith(\".pyc\"):\n",
        "          os.remove(os.path.join(dir_name, item))"
      ],
      "metadata": {
        "id": "03qDLWqqgcbM"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Training New Model**\n",
        "\n",
        "Data yang digunakan merupakan data sel kanker payudara yang diakses melalui Kaggle. Dataset berisi gambar dan label, yaitu untuk train masing-masing berjumlah 24 dan untuk test masing-masing berjumlah 8.\n",
        "\n",
        "Tahap preprocessing yang dilakukan adalah melakukan croping gambar dan label serta me-resize ukurannya menjadi . Selanjutnya dilakukan pairing gambar dan label, sehingga ukurannya menjadi .\n",
        "\n",
        "Sebagai gambaran berikut adalah contoh data yang digunakan"
      ],
      "metadata": {
        "id": "D8c1V2XjGqaX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**cycleGAN training**"
      ],
      "metadata": {
        "id": "F79bMQAuGwrZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python train.py --dataroot \"/content/NucleiSegmentation/dataset\" --name NU_SEG  --gpu_ids 0 --display_id 0 --niter 200 --niter_decay 200 --pool_size 64 --loadSize 256 --fineSize 256 --model \"cycle_gan\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGg4S4G6ghUg",
        "outputId": "33f83080-ab8e-414b-a29c-02d258aaba27"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------- Options ---------------\n",
            "                batchSize: 1                             \n",
            "                    beta1: 0.5                           \n",
            "          checkpoints_dir: ./checkpoints                 \n",
            "           continue_train: False                         \n",
            "                 dataroot: /content/NucleiSegmentation/dataset\t[default: None]\n",
            "             dataset_mode: aligned                       \n",
            "             display_freq: 400                           \n",
            "               display_id: 0                             \t[default: 1]\n",
            "            display_ncols: 4                             \n",
            "             display_port: 8097                          \n",
            "           display_server: http://localhost              \n",
            "          display_winsize: 256                           \n",
            "              epoch_count: 1                             \n",
            "                 fineSize: 256                           \n",
            "                  gpu_ids: 0                             \n",
            "                init_gain: 0.02                          \n",
            "                init_type: normal                        \n",
            "                 input_nc: 3                             \n",
            "                  isTrain: True                          \t[default: None]\n",
            "                 lambda_A: 10.0                          \n",
            "                 lambda_B: 10.0                          \n",
            "          lambda_identity: 0.5                           \n",
            "                 loadSize: 256                           \t[default: 286]\n",
            "                       lr: 0.0002                        \n",
            "           lr_decay_iters: 50                            \n",
            "                lr_policy: lambda                        \n",
            "         max_dataset_size: inf                           \n",
            "                    model: cycle_gan                     \t[default: pix2pix]\n",
            "                 nThreads: 4                             \n",
            "               n_layers_D: 3                             \n",
            "                     name: NU_SEG                        \t[default: experiment_name]\n",
            "                      ndf: 64                            \n",
            "                      ngf: 64                            \n",
            "                    niter: 200                           \t[default: 100]\n",
            "              niter_decay: 200                           \t[default: 100]\n",
            "               no_dropout: True                          \n",
            "                  no_flip: False                         \n",
            "                  no_html: False                         \n",
            "                 no_lsgan: False                         \n",
            "                     norm: instance                      \n",
            "                output_nc: 3                             \n",
            "                    phase: train                         \n",
            "                pool_size: 64                            \t[default: 50]\n",
            "               print_freq: 100                           \n",
            "           resize_or_crop: resize_and_crop               \n",
            "          save_epoch_freq: 5                             \n",
            "         save_latest_freq: 5000                          \n",
            "           serial_batches: False                         \n",
            "                   suffix:                               \n",
            "         update_html_freq: 1000                          \n",
            "                  verbose: False                         \n",
            "          which_direction: AtoB                          \n",
            "              which_epoch: latest                        \n",
            "         which_model_netD: basic                         \n",
            "         which_model_netG: unet_256                      \n",
            "----------------- End -------------------\n",
            "dataset [AlignedDataset] was created\n",
            "/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:490: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  cpuset_checked))\n",
            "#training images = 9\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "initialize network with normal\n",
            "model [CycleGANModel] was created\n",
            "---------- Networks initialized -------------\n",
            "[Network G_A] Total number of parameters : 54.414 M\n",
            "[Network G_B] Total number of parameters : 54.414 M\n",
            "[Network D_A] Total number of parameters : 2.764 M\n",
            "[Network D_B] Total number of parameters : 2.764 M\n",
            "-----------------------------------------------\n",
            "create web directory ./checkpoints/NU_SEG/web...\n",
            "End of epoch 1 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 2 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 3 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 4 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 5, iters 45\n",
            "End of epoch 5 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 6 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 7 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 8 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 9 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 10, iters 90\n",
            "End of epoch 10 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 11 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 12, iters: 1, time: 0.276, data: 0.211) D_A: 0.228 G_A: 0.216 cycle_A: 0.272 idt_A: 0.257 D_B: 0.173 G_B: 0.254 cycle_B: 0.261 idt_B: 0.235 \n",
            "End of epoch 12 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 13 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 14 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 15, iters 135\n",
            "End of epoch 15 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 16 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 17 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 18 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 19 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 20, iters 180\n",
            "End of epoch 20 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 21 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 22 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 23, iters: 2, time: 0.263, data: 0.006) D_A: 0.192 G_A: 0.196 cycle_A: 0.592 idt_A: 0.306 D_B: 0.240 G_B: 0.188 cycle_B: 0.609 idt_B: 0.281 \n",
            "End of epoch 23 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 24 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 25, iters 225\n",
            "End of epoch 25 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 26 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 27 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 28 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 29 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 30, iters 270\n",
            "End of epoch 30 / 400 \t Time Taken: 6 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 31 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 32 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 33 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 34, iters: 3, time: 0.267, data: 0.004) D_A: 0.179 G_A: 0.338 cycle_A: 0.206 idt_A: 0.143 D_B: 0.264 G_B: 0.211 cycle_B: 0.243 idt_B: 0.140 \n",
            "End of epoch 34 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 35, iters 315\n",
            "End of epoch 35 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 36 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 37 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 38 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 39 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 40, iters 360\n",
            "End of epoch 40 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 41 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 42 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 43 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 44 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 45, iters: 4, time: 0.744, data: 0.003) D_A: 0.166 G_A: 0.382 cycle_A: 0.385 idt_A: 0.190 D_B: 0.247 G_B: 0.110 cycle_B: 0.393 idt_B: 0.168 \n",
            "saving the model at the end of epoch 45, iters 405\n",
            "End of epoch 45 / 400 \t Time Taken: 6 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 46 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 47 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 48 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 49 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 50, iters 450\n",
            "End of epoch 50 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 51 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 52 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 53 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 54 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 55, iters 495\n",
            "End of epoch 55 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 56, iters: 5, time: 0.288, data: 0.003) D_A: 0.203 G_A: 0.349 cycle_A: 0.367 idt_A: 0.148 D_B: 0.176 G_B: 0.405 cycle_B: 0.342 idt_B: 0.151 \n",
            "End of epoch 56 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 57 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 58 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 59 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 60, iters 540\n",
            "End of epoch 60 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 61 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 62 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 63 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 64 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 65, iters 585\n",
            "End of epoch 65 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 66 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 67, iters: 6, time: 0.280, data: 0.000) D_A: 0.198 G_A: 0.111 cycle_A: 0.179 idt_A: 0.081 D_B: 0.248 G_B: 0.690 cycle_B: 0.166 idt_B: 0.077 \n",
            "End of epoch 67 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 68 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 69 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 70, iters 630\n",
            "End of epoch 70 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 71 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 72 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 73 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 74 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 75, iters 675\n",
            "End of epoch 75 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 76 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 77 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 78, iters: 7, time: 0.279, data: 0.003) D_A: 0.210 G_A: 0.256 cycle_A: 0.158 idt_A: 0.075 D_B: 0.161 G_B: 0.791 cycle_B: 0.153 idt_B: 0.070 \n",
            "End of epoch 78 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 79 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 80, iters 720\n",
            "End of epoch 80 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 81 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 82 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 83 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 84 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 85, iters 765\n",
            "End of epoch 85 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 86 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 87 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 88 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 89, iters: 8, time: 1.065, data: 0.002) D_A: 0.202 G_A: 0.334 cycle_A: 0.207 idt_A: 0.079 D_B: 0.268 G_B: 0.352 cycle_B: 0.173 idt_B: 0.081 \n",
            "End of epoch 89 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 90, iters 810\n",
            "End of epoch 90 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 91 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 92 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 93 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 94 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 95, iters 855\n",
            "End of epoch 95 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 96 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 97 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 98 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 99 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 100, iters: 9, time: 0.287, data: 0.002) D_A: 0.079 G_A: 0.258 cycle_A: 0.125 idt_A: 0.061 D_B: 0.206 G_B: 0.437 cycle_B: 0.128 idt_B: 0.056 \n",
            "saving the model at the end of epoch 100, iters 900\n",
            "End of epoch 100 / 400 \t Time Taken: 6 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 101 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 102 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 103 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 104 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 105, iters 945\n",
            "End of epoch 105 / 400 \t Time Taken: 6 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 106 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 107 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 108 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 109 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 110, iters 990\n",
            "End of epoch 110 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 111 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 112, iters: 1, time: 0.267, data: 0.186) D_A: 0.201 G_A: 0.269 cycle_A: 0.094 idt_A: 0.054 D_B: 0.158 G_B: 0.202 cycle_B: 0.108 idt_B: 0.047 \n",
            "End of epoch 112 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 113 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 114 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 115, iters 1035\n",
            "End of epoch 115 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 116 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 117 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 118 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 119 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 120, iters 1080\n",
            "End of epoch 120 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 121 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 122 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 123, iters: 2, time: 0.278, data: 0.002) D_A: 0.203 G_A: 0.266 cycle_A: 0.113 idt_A: 0.059 D_B: 0.192 G_B: 0.426 cycle_B: 0.118 idt_B: 0.053 \n",
            "End of epoch 123 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 124 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 125, iters 1125\n",
            "End of epoch 125 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 126 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 127 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 128 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 129 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 130, iters 1170\n",
            "End of epoch 130 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 131 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 132 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 133 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 134, iters: 3, time: 1.400, data: 0.002) D_A: 0.263 G_A: 0.106 cycle_A: 0.131 idt_A: 0.062 D_B: 0.174 G_B: 0.320 cycle_B: 0.116 idt_B: 0.058 \n",
            "End of epoch 134 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 135, iters 1215\n",
            "End of epoch 135 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 136 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 137 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 138 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 139 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 140, iters 1260\n",
            "End of epoch 140 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 141 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 142 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 143 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 144 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 145, iters: 4, time: 0.287, data: 0.000) D_A: 0.223 G_A: 0.214 cycle_A: 0.119 idt_A: 0.048 D_B: 0.124 G_B: 0.208 cycle_B: 0.097 idt_B: 0.051 \n",
            "saving the model at the end of epoch 145, iters 1305\n",
            "End of epoch 146 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 147 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 148 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 149 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 150, iters 1350\n",
            "End of epoch 150 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 151 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 152 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 153 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 154 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 155, iters 1395\n",
            "End of epoch 155 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 156, iters: 5, time: 0.287, data: 0.000) D_A: 0.109 G_A: 0.163 cycle_A: 0.175 idt_A: 0.070 D_B: 0.173 G_B: 0.215 cycle_B: 0.165 idt_B: 0.067 \n",
            "End of epoch 156 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 157 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 158 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 159 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 160, iters 1440\n",
            "End of epoch 160 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 161 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 162 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 163 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 164 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 165, iters 1485\n",
            "End of epoch 165 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 166 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 167, iters: 6, time: 0.280, data: 0.003) D_A: 0.210 G_A: 0.515 cycle_A: 0.087 idt_A: 0.041 D_B: 0.192 G_B: 0.390 cycle_B: 0.087 idt_B: 0.038 \n",
            "End of epoch 167 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 168 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 169 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 170, iters 1530\n",
            "End of epoch 170 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 171 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 172 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 173 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 174 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 175, iters 1575\n",
            "End of epoch 175 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 176 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 177 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 178, iters: 7, time: 1.649, data: 0.002) D_A: 0.124 G_A: 0.380 cycle_A: 0.145 idt_A: 0.063 D_B: 0.184 G_B: 0.222 cycle_B: 0.146 idt_B: 0.058 \n",
            "End of epoch 178 / 400 \t Time Taken: 3 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 179 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 180, iters 1620\n",
            "End of epoch 180 / 400 \t Time Taken: 6 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 181 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 182 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 183 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 184 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 185, iters 1665\n",
            "End of epoch 185 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 186 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 187 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 188 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "(epoch: 189, iters: 8, time: 0.285, data: 0.002) D_A: 0.136 G_A: 0.191 cycle_A: 0.114 idt_A: 0.046 D_B: 0.172 G_B: 0.450 cycle_B: 0.098 idt_B: 0.048 \n",
            "End of epoch 189 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 190, iters 1710\n",
            "End of epoch 190 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 191 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 192 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 193 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 194 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "saving the model at the end of epoch 195, iters 1755\n",
            "End of epoch 195 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 196 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 197 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 198 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0002000\n",
            "End of epoch 199 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001990\n",
            "(epoch: 200, iters: 9, time: 0.286, data: 0.000) D_A: 0.202 G_A: 0.181 cycle_A: 0.077 idt_A: 0.035 D_B: 0.211 G_B: 0.206 cycle_B: 0.072 idt_B: 0.036 \n",
            "saving the model at the end of epoch 200, iters 1800\n",
            "End of epoch 200 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001980\n",
            "End of epoch 201 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001970\n",
            "End of epoch 202 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001960\n",
            "End of epoch 203 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001950\n",
            "End of epoch 204 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001940\n",
            "saving the model at the end of epoch 205, iters 1845\n",
            "End of epoch 205 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001930\n",
            "End of epoch 206 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001920\n",
            "End of epoch 207 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001910\n",
            "End of epoch 208 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001900\n",
            "End of epoch 209 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001891\n",
            "saving the model at the end of epoch 210, iters 1890\n",
            "End of epoch 210 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001881\n",
            "End of epoch 211 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001871\n",
            "(epoch: 212, iters: 1, time: 0.282, data: 0.202) D_A: 0.220 G_A: 0.292 cycle_A: 0.057 idt_A: 0.028 D_B: 0.226 G_B: 0.266 cycle_B: 0.064 idt_B: 0.024 \n",
            "End of epoch 212 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001861\n",
            "End of epoch 213 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001851\n",
            "End of epoch 214 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001841\n",
            "saving the model at the end of epoch 215, iters 1935\n",
            "End of epoch 215 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001831\n",
            "End of epoch 216 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001821\n",
            "End of epoch 217 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001811\n",
            "End of epoch 218 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001801\n",
            "End of epoch 219 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001791\n",
            "saving the model at the end of epoch 220, iters 1980\n",
            "End of epoch 220 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001781\n",
            "End of epoch 221 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001771\n",
            "End of epoch 222 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001761\n",
            "(epoch: 223, iters: 2, time: 2.034, data: 0.003) D_A: 0.159 G_A: 0.179 cycle_A: 0.082 idt_A: 0.039 D_B: 0.229 G_B: 0.208 cycle_B: 0.086 idt_B: 0.037 \n",
            "End of epoch 223 / 400 \t Time Taken: 4 sec\n",
            "learning rate = 0.0001751\n",
            "End of epoch 224 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001741\n",
            "saving the model at the end of epoch 225, iters 2025\n",
            "End of epoch 225 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001731\n",
            "End of epoch 226 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001721\n",
            "End of epoch 227 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001711\n",
            "End of epoch 228 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001701\n",
            "End of epoch 229 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001692\n",
            "saving the model at the end of epoch 230, iters 2070\n",
            "End of epoch 230 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001682\n",
            "End of epoch 231 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001672\n",
            "End of epoch 232 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001662\n",
            "End of epoch 233 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001652\n",
            "(epoch: 234, iters: 3, time: 0.277, data: 0.000) D_A: 0.241 G_A: 0.344 cycle_A: 0.057 idt_A: 0.025 D_B: 0.222 G_B: 0.306 cycle_B: 0.060 idt_B: 0.022 \n",
            "End of epoch 234 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001642\n",
            "saving the model at the end of epoch 235, iters 2115\n",
            "End of epoch 235 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001632\n",
            "End of epoch 237 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001612\n",
            "End of epoch 238 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001602\n",
            "End of epoch 239 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001592\n",
            "saving the model at the end of epoch 240, iters 2160\n",
            "End of epoch 240 / 400 \t Time Taken: 6 sec\n",
            "learning rate = 0.0001582\n",
            "End of epoch 241 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001572\n",
            "End of epoch 242 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001562\n",
            "End of epoch 243 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001552\n",
            "End of epoch 244 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001542\n",
            "(epoch: 245, iters: 4, time: 0.283, data: 0.000) D_A: 0.189 G_A: 0.316 cycle_A: 0.054 idt_A: 0.028 D_B: 0.102 G_B: 0.239 cycle_B: 0.060 idt_B: 0.024 \n",
            "saving the model at the end of epoch 245, iters 2205\n",
            "End of epoch 245 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001532\n",
            "End of epoch 246 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001522\n",
            "End of epoch 247 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001512\n",
            "End of epoch 248 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001502\n",
            "End of epoch 249 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001493\n",
            "saving the model at the end of epoch 250, iters 2250\n",
            "End of epoch 250 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001483\n",
            "End of epoch 251 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001473\n",
            "End of epoch 252 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001463\n",
            "End of epoch 253 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001453\n",
            "End of epoch 254 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001443\n",
            "saving the model at the end of epoch 255, iters 2295\n",
            "End of epoch 255 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001433\n",
            "(epoch: 256, iters: 5, time: 0.281, data: 0.002) D_A: 0.269 G_A: 0.490 cycle_A: 0.054 idt_A: 0.024 D_B: 0.158 G_B: 0.269 cycle_B: 0.057 idt_B: 0.021 \n",
            "End of epoch 256 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001423\n",
            "End of epoch 257 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001413\n",
            "End of epoch 258 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001403\n",
            "End of epoch 259 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001393\n",
            "saving the model at the end of epoch 260, iters 2340\n",
            "End of epoch 260 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001383\n",
            "End of epoch 261 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001373\n",
            "End of epoch 262 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001363\n",
            "End of epoch 263 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001353\n",
            "End of epoch 264 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001343\n",
            "saving the model at the end of epoch 265, iters 2385\n",
            "End of epoch 265 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001333\n",
            "End of epoch 266 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001323\n",
            "(epoch: 267, iters: 6, time: 2.331, data: 0.002) D_A: 0.165 G_A: 0.308 cycle_A: 0.079 idt_A: 0.031 D_B: 0.193 G_B: 0.359 cycle_B: 0.066 idt_B: 0.036 \n",
            "End of epoch 267 / 400 \t Time Taken: 4 sec\n",
            "learning rate = 0.0001313\n",
            "End of epoch 268 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001303\n",
            "End of epoch 269 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001294\n",
            "saving the model at the end of epoch 270, iters 2430\n",
            "End of epoch 270 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001284\n",
            "End of epoch 271 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001274\n",
            "End of epoch 272 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001264\n",
            "End of epoch 273 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001254\n",
            "End of epoch 274 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001244\n",
            "saving the model at the end of epoch 275, iters 2475\n",
            "End of epoch 275 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001234\n",
            "End of epoch 276 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001224\n",
            "End of epoch 277 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001214\n",
            "(epoch: 278, iters: 7, time: 0.280, data: 0.002) D_A: 0.172 G_A: 0.311 cycle_A: 0.064 idt_A: 0.029 D_B: 0.201 G_B: 0.276 cycle_B: 0.064 idt_B: 0.028 \n",
            "End of epoch 278 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001204\n",
            "End of epoch 279 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001194\n",
            "saving the model at the end of epoch 280, iters 2520\n",
            "End of epoch 280 / 400 \t Time Taken: 6 sec\n",
            "learning rate = 0.0001184\n",
            "End of epoch 281 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001174\n",
            "End of epoch 282 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001164\n",
            "End of epoch 283 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001154\n",
            "End of epoch 284 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001144\n",
            "saving the model at the end of epoch 285, iters 2565\n",
            "End of epoch 285 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001134\n",
            "End of epoch 286 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001124\n",
            "End of epoch 287 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001114\n",
            "End of epoch 288 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001104\n",
            "(epoch: 289, iters: 8, time: 0.284, data: 0.002) D_A: 0.187 G_A: 0.326 cycle_A: 0.076 idt_A: 0.030 D_B: 0.200 G_B: 0.424 cycle_B: 0.064 idt_B: 0.033 \n",
            "End of epoch 289 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001095\n",
            "saving the model at the end of epoch 290, iters 2610\n",
            "End of epoch 290 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001085\n",
            "End of epoch 291 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001075\n",
            "End of epoch 292 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001065\n",
            "End of epoch 293 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001055\n",
            "End of epoch 294 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001045\n",
            "saving the model at the end of epoch 295, iters 2655\n",
            "End of epoch 295 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0001035\n",
            "End of epoch 296 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001025\n",
            "End of epoch 297 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001015\n",
            "End of epoch 298 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0001005\n",
            "End of epoch 299 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000995\n",
            "(epoch: 300, iters: 9, time: 0.291, data: 0.000) D_A: 0.198 G_A: 0.419 cycle_A: 0.062 idt_A: 0.028 D_B: 0.202 G_B: 0.417 cycle_B: 0.062 idt_B: 0.027 \n",
            "saving the model at the end of epoch 300, iters 2700\n",
            "End of epoch 300 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000985\n",
            "End of epoch 301 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000975\n",
            "End of epoch 302 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000965\n",
            "End of epoch 303 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000955\n",
            "End of epoch 304 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000945\n",
            "saving the model at the end of epoch 305, iters 2745\n",
            "End of epoch 305 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000935\n",
            "End of epoch 306 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000925\n",
            "End of epoch 307 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000915\n",
            "End of epoch 308 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000905\n",
            "End of epoch 309 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000896\n",
            "saving the model at the end of epoch 310, iters 2790\n",
            "End of epoch 310 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000886\n",
            "End of epoch 311 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000876\n",
            "(epoch: 312, iters: 1, time: 2.612, data: 0.246) D_A: 0.188 G_A: 0.390 cycle_A: 0.075 idt_A: 0.030 D_B: 0.192 G_B: 0.402 cycle_B: 0.063 idt_B: 0.033 \n",
            "End of epoch 312 / 400 \t Time Taken: 4 sec\n",
            "learning rate = 0.0000866\n",
            "End of epoch 313 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000856\n",
            "End of epoch 314 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000846\n",
            "saving the model at the end of epoch 315, iters 2835\n",
            "End of epoch 315 / 400 \t Time Taken: 6 sec\n",
            "learning rate = 0.0000836\n",
            "End of epoch 316 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000826\n",
            "End of epoch 317 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000816\n",
            "End of epoch 318 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000806\n",
            "End of epoch 319 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000796\n",
            "saving the model at the end of epoch 320, iters 2880\n",
            "End of epoch 320 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000786\n",
            "End of epoch 321 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000776\n",
            "End of epoch 322 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000766\n",
            "(epoch: 323, iters: 2, time: 0.278, data: 0.002) D_A: 0.203 G_A: 0.369 cycle_A: 0.047 idt_A: 0.035 D_B: 0.183 G_B: 0.401 cycle_B: 0.073 idt_B: 0.022 \n",
            "End of epoch 323 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000756\n",
            "End of epoch 324 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000746\n",
            "saving the model at the end of epoch 325, iters 2925\n",
            "End of epoch 325 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000736\n",
            "End of epoch 326 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000726\n",
            "End of epoch 327 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000716\n",
            "End of epoch 328 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000706\n",
            "End of epoch 329 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000697\n",
            "saving the model at the end of epoch 330, iters 2970\n",
            "End of epoch 330 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000687\n",
            "End of epoch 331 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000677\n",
            "End of epoch 332 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000667\n",
            "End of epoch 333 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000657\n",
            "(epoch: 334, iters: 3, time: 0.278, data: 0.002) D_A: 0.166 G_A: 0.374 cycle_A: 0.094 idt_A: 0.045 D_B: 0.179 G_B: 0.281 cycle_B: 0.093 idt_B: 0.042 \n",
            "End of epoch 334 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000647\n",
            "saving the model at the end of epoch 335, iters 3015\n",
            "End of epoch 335 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000637\n",
            "End of epoch 336 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000627\n",
            "End of epoch 337 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000617\n",
            "End of epoch 338 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000607\n",
            "End of epoch 339 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000597\n",
            "saving the model at the end of epoch 340, iters 3060\n",
            "End of epoch 340 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000587\n",
            "End of epoch 341 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000577\n",
            "End of epoch 342 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000567\n",
            "End of epoch 343 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000557\n",
            "End of epoch 344 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000547\n",
            "(epoch: 345, iters: 4, time: 0.288, data: 0.002) D_A: 0.239 G_A: 0.322 cycle_A: 0.046 idt_A: 0.021 D_B: 0.230 G_B: 0.260 cycle_B: 0.049 idt_B: 0.019 \n",
            "saving the model at the end of epoch 345, iters 3105\n",
            "End of epoch 345 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000537\n",
            "End of epoch 346 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000527\n",
            "End of epoch 347 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000517\n",
            "End of epoch 348 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000507\n",
            "End of epoch 349 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000498\n",
            "saving the model at the end of epoch 350, iters 3150\n",
            "End of epoch 350 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000488\n",
            "End of epoch 351 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000478\n",
            "End of epoch 352 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000468\n",
            "End of epoch 353 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000458\n",
            "End of epoch 354 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000448\n",
            "saving the model at the end of epoch 355, iters 3195\n",
            "End of epoch 355 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000438\n",
            "(epoch: 356, iters: 5, time: 2.954, data: 0.000) D_A: 0.187 G_A: 0.298 cycle_A: 0.094 idt_A: 0.044 D_B: 0.174 G_B: 0.291 cycle_B: 0.093 idt_B: 0.042 \n",
            "End of epoch 356 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000428\n",
            "End of epoch 357 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000418\n",
            "End of epoch 358 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000408\n",
            "End of epoch 359 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000398\n",
            "saving the model at the end of epoch 360, iters 3240\n",
            "End of epoch 360 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000388\n",
            "End of epoch 361 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000378\n",
            "End of epoch 362 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000368\n",
            "End of epoch 363 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000358\n",
            "End of epoch 364 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000348\n",
            "saving the model at the end of epoch 365, iters 3285\n",
            "End of epoch 365 / 400 \t Time Taken: 6 sec\n",
            "learning rate = 0.0000338\n",
            "(epoch: 367, iters: 6, time: 0.278, data: 0.000) D_A: 0.232 G_A: 0.345 cycle_A: 0.059 idt_A: 0.028 D_B: 0.244 G_B: 0.310 cycle_B: 0.059 idt_B: 0.026 \n",
            "End of epoch 367 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000318\n",
            "End of epoch 368 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000308\n",
            "End of epoch 369 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000299\n",
            "saving the model at the end of epoch 370, iters 3330\n",
            "End of epoch 370 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000289\n",
            "End of epoch 371 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000279\n",
            "End of epoch 372 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000269\n",
            "End of epoch 373 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000259\n",
            "End of epoch 374 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000249\n",
            "saving the model at the end of epoch 375, iters 3375\n",
            "End of epoch 375 / 400 \t Time Taken: 6 sec\n",
            "learning rate = 0.0000239\n",
            "End of epoch 376 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000229\n",
            "End of epoch 377 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000219\n",
            "(epoch: 378, iters: 7, time: 0.275, data: 0.000) D_A: 0.235 G_A: 0.342 cycle_A: 0.058 idt_A: 0.027 D_B: 0.212 G_B: 0.325 cycle_B: 0.059 idt_B: 0.026 \n",
            "End of epoch 378 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000209\n",
            "End of epoch 379 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000199\n",
            "saving the model at the end of epoch 380, iters 3420\n",
            "End of epoch 380 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000189\n",
            "End of epoch 381 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000179\n",
            "End of epoch 382 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000169\n",
            "End of epoch 383 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000159\n",
            "End of epoch 384 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000149\n",
            "saving the model at the end of epoch 385, iters 3465\n",
            "End of epoch 385 / 400 \t Time Taken: 6 sec\n",
            "learning rate = 0.0000139\n",
            "End of epoch 386 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000129\n",
            "End of epoch 387 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000119\n",
            "End of epoch 388 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000109\n",
            "(epoch: 389, iters: 8, time: 0.285, data: 0.000) D_A: 0.198 G_A: 0.333 cycle_A: 0.075 idt_A: 0.033 D_B: 0.209 G_B: 0.338 cycle_B: 0.070 idt_B: 0.035 \n",
            "End of epoch 389 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000100\n",
            "saving the model at the end of epoch 390, iters 3510\n",
            "End of epoch 390 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000090\n",
            "End of epoch 391 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000080\n",
            "End of epoch 392 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000070\n",
            "End of epoch 393 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000060\n",
            "End of epoch 394 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000050\n",
            "saving the model at the end of epoch 395, iters 3555\n",
            "End of epoch 395 / 400 \t Time Taken: 5 sec\n",
            "learning rate = 0.0000040\n",
            "End of epoch 396 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000030\n",
            "End of epoch 397 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000020\n",
            "End of epoch 398 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000010\n",
            "End of epoch 399 / 400 \t Time Taken: 2 sec\n",
            "learning rate = 0.0000000\n",
            "(epoch: 400, iters: 9, time: 3.223, data: 0.000) D_A: 0.217 G_A: 0.280 cycle_A: 0.046 idt_A: 0.024 D_B: 0.215 G_B: 0.263 cycle_B: 0.052 idt_B: 0.021 \n",
            "saving the model at the end of epoch 400, iters 3600\n",
            "End of epoch 400 / 400 \t Time Taken: 8 sec\n",
            "learning rate = -0.0000010\n"
          ]
        }
      ]
    }
  ]
}